{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_path = '/kaggle/input/petfinder-adoption-prediction/train/train.csv'\ntest_path = '/kaggle/input/petfinder-adoption-prediction/test/test.csv'\nsub_path = '/kaggle/input/petfinder-adoption-prediction/test/sample_submission.csv'\n\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nsub = pd.read_csv(sub_path)\n\ntrain['dataset_type'] = 'train'\ntest['dataset_type'] = 'test'\n\nall_data = pd.concat([train, test])\nall_data.head(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nnumeric_cols = train.select_dtypes(include='number').columns\nnumeric_cols_length = len(numeric_cols)  \nprint('numeric_cols_length = {}'.format(numeric_cols_length))\n#\ncorr = train.select_dtypes(include='number').corr()\nplt.figure(figsize=(16,6))\ncorr['AdoptionSpeed'].sort_values(ascending=False)[1:].plot(kind='bar')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fealtures_to_use = ['Breed1', 'Age', 'Quantity', 'Gender', 'MaturitySize', 'Health', 'Color1', 'Color2', 'Color3', 'Vaccinated','Sterilized','Type','FurLength']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = train[[col for col in fealtures_to_use if col in train.columns]] #14993 rows \ntrain_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = test[[col for col in fealtures_to_use if col in test.columns]]  #3972 rows\ntest_dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**cohen_kappa_score function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\ndef kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, KFold\n\n#5 class\nn_fold = 5\n\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['AdoptionSpeed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport time\n#ML Algoirthm\n#from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n#import sklearn.linear_model as linear_model\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\n#from sklearn.svm import SVR\n\n#from sklearn.ensemble import GradientBoostingRegressor\n#from xgboost import XGBRegressor\n#from mlxtend.regressor import StackingCVRegressor\n\nresult_dict_lgb = {}\nprediction = np.zeros((len(test_dataset), 5))\nscores = []\n\nX = train_dataset\nX_test = test_dataset\n\nparams = {'num_leaves': 512,\n        #  'min_data_in_leaf': 60,\n         'objective': 'multiclass',\n         'max_depth': -1,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 3,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n        #  \"lambda_l1\": 0.1,\n         # \"lambda_l2\": 0.1,\n         \"random_state\": 42,          \n         \"verbosity\": -1,\n         \"num_class\": 5}\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n    #chia tập train và valid\n    gc.collect()\n    print('Fold', fold_n + 1, 'started at', time.ctime(), 'with (train_index, valid_index):', train_index, valid_index)\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    #\n    train_data = lgb.Dataset(X_train, label=y_train)\n    valid_data = lgb.Dataset(X_valid, label=y_valid)\n    \n    #Build model lightgbm\n    model = lgb.train(params,\n                    train_data,\n                    num_boost_round=20000,\n                    valid_sets = [train_data, valid_data],\n                    verbose_eval=500,\n                    early_stopping_rounds = 200)\n    #prediction cho tập valid\n    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    \n    scores.append(kappa(y_valid, y_pred_valid.argmax(1)))\n    print('Fold kappa:', kappa(y_valid, y_pred_valid.argmax(1)))\n    print('')\n    prediction += y_pred\n\n#chia lấy trung bình    \nprediction /= n_fold\n\nprint('scores kappa: ', scores)    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\nresult_dict_lgb['prediction'] = prediction        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\nimport xgboost as xgb\nresult_dict_xgb = {}\nprediction = np.zeros((len(test_dataset), 5))\nscores = []\n\nX = train_dataset\nX_test = test_dataset\n\n#xem thêm parameters tai: https://xgboost.readthedocs.io/en/latest/parameter.html\nparams = {'eta': 0.01, \n          'max_depth': 9, \n          'subsample': 0.9, \n          'colsample_bytree': 0.9, \n          'objective': 'multi:softprob', \n          'eval_metric': 'merror', \n          'silent': True, \n          'nthread': 4, \n          'num_class': 5}\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n    gc.collect()\n    print('Fold', fold_n + 1, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    #\n    train_data = xgb.DMatrix(data=X_train, label=y_train)\n    valid_data = xgb.DMatrix(data=X_valid, label=y_valid)\n\n    watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n    model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n    y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n    y_pred = model.predict(xgb.DMatrix(X_test), ntree_limit=model.best_ntree_limit)\n            \n    \n    print('y_valid:', y_valid)\n    print('y_pred_valid:', y_pred_valid.argmax(1))\n    #\n    scores.append(kappa(y_valid, y_pred_valid.argmax(1)))\n    print('Fold kappa:', kappa(y_valid, y_pred_valid.argmax(1)))\n    print('')\n    prediction += y_pred\n    \nprediction /= n_fold\n\nprint('scores kappa: ', scores)    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\nresult_dict_xgb['prediction'] = prediction      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nresult_dict_gbc = {}\nprediction = np.zeros((len(test_dataset)))\nscores = []\n\nX = train_dataset\nX_test = test_dataset\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n    gc.collect()\n    print('Fold', fold_n + 1, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    #\n    clf = GradientBoostingClassifier(random_state=0)\n    clf.fit(X_train, y_train)\n    \n    y_pred_valid = clf.predict(X_valid)\n    y_pred = clf.predict(X_test)\n        \n    scores.append(kappa(y_valid, y_pred_valid))\n    print('Fold kappa:', kappa(y_valid, y_pred_valid))\n    prediction += y_pred\n    \nprediction /= n_fold\n\nprint('scores kappa: ', scores)    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\nresult_dict_gbc['prediction'] = prediction ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keras specific\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nresult_dict_MLP = {}\nprediction = np.zeros((len(test_dataset)))\nscores = []\n\nX = train_dataset\nX_test = test_dataset\n\nsc = StandardScaler()\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n    gc.collect()\n    print('Fold', fold_n + 1, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    X_train = sc.fit_transform(X_train)\n    X_valid = sc.fit_transform(X_valid)\n    X_test = sc.fit_transform(X_test)\n    \n    model = MLPClassifier(max_iter= 500, activation = 'relu',solver='adam',random_state=1)\n    \n    # build the model\n    model.fit(X_train, y_train)\n\n    \n    \n    y_pred_valid = model.predict(X_valid)\n    y_pred = model.predict(X_test)\n        \n    scores.append(kappa(y_valid, y_pred_valid))\n    print('Fold kappa:', kappa(y_valid, y_pred_valid))\n    \n    print('y_pred:', y_pred)\n    prediction += y_pred\n    \nprediction /= n_fold\n\nprint('scores kappa: ', scores)    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\nresult_dict_MLP['prediction'] = prediction ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_prediction_lgb = (result_dict_lgb['prediction']).argmax(1)\nsubmission_lgb = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [int(i) for i in submission_prediction_lgb]})\nsubmission_lgb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_prediction_xgb = (result_dict_xgb['prediction']).argmax(1)\nsubmission_xgb = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [int(i) for i in submission_prediction_xgb]})\nsubmission_xgb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_prediction_gbc = (result_dict_gbc['prediction'])\nsubmission_gbc = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [float(i) for i in submission_prediction_gbc]})\nsubmission_gbc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_prediction_MLP = (result_dict_MLP['prediction'])\nsubmission_MLP = pd.DataFrame({'PetID': sub.PetID, \n                               'AdoptionSpeed': [float(i) for i in submission_prediction_MLP],\n                              }\n                             )\nsubmission_MLP.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_prediction_all = (result_dict_lgb['prediction'].argmax(1) + result_dict_xgb['prediction'].argmax(1) + result_dict_gbc['prediction'] + result_dict_MLP['prediction']) / 4\nsubmission_all = pd.DataFrame({'PetID': sub.PetID, \n                           'AdoptionSpeed_lgb': [(i) for i in submission_prediction_lgb], #lgb\n                           'AdoptionSpeed_xgb': [(i) for i in submission_prediction_xgb], #xgboost\n                           'AdoptionSpeed_gbc': [int(round(i)) for i in submission_prediction_gbc], #GradientBoostingClassifier  \n                           'AdoptionSpeed_MLP': [int(round(i)) for i in submission_prediction_MLP], #MLP      \n                           'AdoptionSpeed': [int(round(i)) for i in submission_prediction_all]\n                          })\nsubmission_all.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission = pd.DataFrame({'PetID': sub.PetID,\n                         #  'AdoptionSpeed': [int(i) for i in submission_all]\n                         # })\n#submission.to_csv('submission.csv')\nsubmission = submission_all[['PetID', 'AdoptionSpeed']]\n\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}